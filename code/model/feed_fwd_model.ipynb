{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNw6v_yeKcoh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import chain\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import tqdm\n",
        "\n",
        "import copy\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler    \n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n",
        "                             roc_curve, recall_score, classification_report, f1_score,\n",
        "                             precision_recall_fscore_support, confusion_matrix,\n",
        "                             precision_score, recall_score)\n",
        "\n",
        "import torch.utils.data as data_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtHibYwzXxuO"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3se9GEr5LoiP"
      },
      "source": [
        "## Read in data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GThfy3ccLn27"
      },
      "outputs": [],
      "source": [
        "train = np.load('/content/baseline_train_smote.npz')\n",
        "#train = np.load(\"/content/baseline_train.npz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrEi-cSOKlew"
      },
      "outputs": [],
      "source": [
        "train[\"x\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJ8MpV49ZTs4"
      },
      "outputs": [],
      "source": [
        "train[\"y\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7qV4WVR0_gz"
      },
      "outputs": [],
      "source": [
        "#validation = np.load('/content/baseline_validation_smote.npz')\n",
        "validation = np.load('/content/baseline_validation.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4bfDZqv1DYH"
      },
      "outputs": [],
      "source": [
        "validation[\"x\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kakPUBm1E_W"
      },
      "outputs": [],
      "source": [
        "validation[\"y\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8H8PP9S1G6k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kI2gjDDvaZjN"
      },
      "outputs": [],
      "source": [
        "test = np.load(\"/content/baseline_test.npz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFxLaqIHagPx"
      },
      "outputs": [],
      "source": [
        "#test[\"x\"].shape "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IFLH1wxajHr"
      },
      "outputs": [],
      "source": [
        "#test[\"y\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ayxyInPrX-N"
      },
      "outputs": [],
      "source": [
        "unique_labels, label_counts = np.unique(train[\"y\"], return_counts=True)\n",
        "print(f\"Count of negative vs positive labels: {label_counts}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbZ01gvfsdUc"
      },
      "outputs": [],
      "source": [
        "231/755844"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOjaBYRhrhQY"
      },
      "outputs": [],
      "source": [
        "class_weights = [1/c for c in label_counts]\n",
        "class_weights "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEYi6x_er2PA"
      },
      "outputs": [],
      "source": [
        "# Assign weights to samples \n",
        "sample_weights = [class_weights[int(l)] for l in train[\"y\"]]\n",
        "sampler = WeightedRandomSampler(sample_weights, len(train[\"y\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4IiKdwVsSQO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtce-YwBZ9sT"
      },
      "outputs": [],
      "source": [
        "# Load data \n",
        "minibatch_size = 500\n",
        "\n",
        "X_train = torch.tensor(train[\"x\"], dtype=torch.float32).to(device)\n",
        "y_train = torch.tensor(train[\"y\"], dtype=torch.float32).reshape(-1,1).to(device)\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
        "                                           batch_size=minibatch_size, \n",
        "                                           shuffle=True) \n",
        "\n",
        "X_val = torch.tensor(validation[\"x\"], dtype=torch.float32).to(device)\n",
        "y_val = torch.tensor(validation[\"y\"], dtype=torch.float32).reshape(-1,1).to(device)\n",
        "val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "X_test = torch.tensor(test[\"x\"], dtype=torch.float32).to(device)\n",
        "y_test = torch.tensor(test[\"y\"], dtype=torch.float32).reshape(-1,1).to(device)\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcPtWlu2Zosi"
      },
      "source": [
        "## Model setup "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmtlcRp6a7-W"
      },
      "outputs": [],
      "source": [
        "class FF1(nn.Module):\n",
        "    def __init__(self, input_size, hl1, hl2):\n",
        "        super().__init__()\n",
        "        self.hl1 = nn.Linear(input_size, hl1)\n",
        "        self.hl2 = nn.Linear(hl1, hl2)\n",
        "        self.output = nn.Linear(hl2, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.d1 = nn.Dropout(p=0.7)\n",
        "        self.d2 = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.hl1(x))\n",
        "        x = self.d1(x) # added\n",
        "        x = self.relu(self.hl2(x))\n",
        "        x = self.d2(x) # added \n",
        "        x = self.sigmoid(self.output(x))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FF1_best(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hl1 = nn.Linear(input_size, 24)\n",
        "        self.hl2 = nn.Linear(24, 29)\n",
        "        self.hl3 = nn.Linear(29, 51)\n",
        "        self.output = nn.Linear(51, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.d1 = nn.Dropout(p=0.624642706940751)\n",
        "        self.d2 = nn.Dropout(p=0.5871473304012731)\n",
        "        self.d3 = nn.Dropout(p=0.5806565872839119)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.hl1(x))\n",
        "        x = self.d1(x) # added\n",
        "        x = self.relu(self.hl2(x))\n",
        "        x = self.d2(x) # added \n",
        "        x = self.relu(self.hl3(x))\n",
        "        x = self.d3(x)\n",
        "        x = self.sigmoid(self.output(x))\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZdpEF6x0YReu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zi4f6DLw4FPl"
      },
      "outputs": [],
      "source": [
        "class FF2(nn.Module):\n",
        "    def __init__(self, input_size, hl1, hl2, hl3, hl4, hl5):\n",
        "        super().__init__()\n",
        "        self.hl1 = nn.Linear(input_size, hl1)\n",
        "        self.hl2 = nn.Linear(hl1, hl2)\n",
        "        self.hl3 = nn.Linear(hl2, hl3)\n",
        "        self.hl4 = nn.Linear(hl3, hl4)\n",
        "        self.hl5 = nn.Linear(hl4, hl5)\n",
        "        self.output = nn.Linear(hl5, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.hl1(x))\n",
        "        x = self.relu(self.hl2(x))\n",
        "        x = self.relu(self.hl3(x))\n",
        "        x = self.relu(self.hl4(x))\n",
        "        x = self.relu(self.hl5(x))\n",
        "        x = self.sigmoid(self.output(x))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhcLtwHaHsSF"
      },
      "outputs": [],
      "source": [
        "# Initialize model \n",
        "#input_size = 106\n",
        "#hl1 = 66 \n",
        "#hl2 = 44\n",
        "#hl1 = 100 \n",
        "#hl2 = 80\n",
        "#hl3 = 80\n",
        "#hl4 = 60\n",
        "#hl5 = 40\n",
        "\n",
        "# prediction threshold\n",
        "pred_threshold_low = 0.0003\n",
        "pred_threshold_normal = 0.5\n",
        "\n",
        "curr_model = FF1_best()\n",
        "#curr_model = FF1(input_size, hl1, hl2)\n",
        "#curr_model = FF2(input_size, hl1, hl2, hl3, hl4, hl5)\n",
        "curr_model = curr_model.to(device)\n",
        "\n",
        "# Initialize Hyperparameters\n",
        "#learning_rate = 0.001\n",
        "learning_rate = 0.00028934840305875725\n",
        "num_epochs = 200\n",
        "criterion = nn.BCELoss()\n",
        "#criterion = nn.BCEWithLogitsLoss()\n",
        "#optimizer = torch.optim.Adam(curr_model.parameters(), \n",
        "#                             lr=learning_rate, \n",
        "#                             weight_decay=10e-05)\n",
        "optimizer = torch.optim.RMSprop(curr_model.parameters(), \n",
        "                             lr=learning_rate, \n",
        "                             weight_decay=10e-05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SSD8QoSa_wr"
      },
      "outputs": [],
      "source": [
        "print(sum([x.reshape(-1).shape[0] for x in curr_model.parameters()])) #number of parameters "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJOMYwyzJZiW"
      },
      "outputs": [],
      "source": [
        "train_results = {}\n",
        "train_results[\"train_loss\"] = []\n",
        "train_results[\"epoch\"] = []\n",
        "train_results[\"train_pred\"] = []\n",
        "train_results[\"train_label\"] = []\n",
        "train_results[\"train_pred_label_0pt0003\"] = []\n",
        "train_results[\"train_pred_label_0pt5\"] = []\n",
        "\n",
        "train_metrics = {}\n",
        "train_metrics[\"f1_fraud_0pt0003\"] = []\n",
        "train_metrics[\"f1_fraud_0pt5\"] = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  h = np.array([])\n",
        "  for data, label in train_loader:\n",
        "    curr_f1_scores = []\n",
        "\n",
        "    # move data and label to device\n",
        "    data = data.to(device)\n",
        "    label = label.to(device)\n",
        "    \n",
        "    # forward\n",
        "    output = curr_model(data)\n",
        "    loss = criterion(output, label)\n",
        "    h = np.append(h, loss.item())\n",
        "\n",
        "    # backward \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "  #mean_f1 = np.mean(curr_f1_scores)\n",
        "  #print(f\"Epoch {epoch} fraud mean F1 score at 0.5 threshold: {mean_f1}\")\n",
        "  #train_metrics[\"f1_fraud_0pt5\"].append(mean_f1)\n",
        "\n",
        "  # Record loss values \n",
        "  mean_loss = np.mean(h)\n",
        "  print('epoch [{}/{}], loss:{:.4f}'\n",
        "          .format(epoch + 1, num_epochs, mean_loss))\n",
        "  #train_results['train_loss'].append(mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd8e5jxGGD8m"
      },
      "outputs": [],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uM7J0-WXGPTf"
      },
      "outputs": [],
      "source": [
        "train_summary_metrics = {}\n",
        "train_summary_metrics[\"train_pred\"] = []\n",
        "train_summary_metrics[\"train_label\"] = []\n",
        "\n",
        "curr_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  train_output = curr_model(X_train)\n",
        "  train_output = list(chain.from_iterable(train_output.tolist()))\n",
        "\n",
        "  train_summary_metrics[\"train_pred\"] = train_output\n",
        "  train_summary_metrics[\"train_label\"] = list(chain.from_iterable(y_train.tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htLNAZDZe-2N"
      },
      "outputs": [],
      "source": [
        "train_summary_metrics_df = pd.DataFrame(train_summary_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9o26gtLgRPE"
      },
      "outputs": [],
      "source": [
        "f1_score(train_summary_metrics_df.train_label, \n",
        "                                 train_summary_metrics_df.train_pred.round())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQMpJP2jB1QD"
      },
      "outputs": [],
      "source": [
        "#torch.save(curr_model.state_dict(), \"/content/smote_model_3_layers_initial_dropout_100_epoch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahKf4-Dc3ouI"
      },
      "outputs": [],
      "source": [
        "# Store results for plotting \n",
        "validation_results = {}\n",
        "validation_results['validation_loss'] = []\n",
        "validation_results['validation_pred'] = []\n",
        "validation_results['validation_true_label'] = []\n",
        "\n",
        "# To store accuracy\n",
        "accuracy = {}\n",
        "accuracy['validation_accuracy'] = []\n",
        "accuracy['test_accuracy'] = []\n",
        "\n",
        "# Evaluate accuracy on validation data \n",
        "curr_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, label in val_loader:\n",
        "        # move data and label to device\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        output = curr_model(data).to(device)\n",
        "        #print(f\"Output: {output}\")\n",
        "\n",
        "        # store relevant values \n",
        "        curr_loss = criterion(output, label).item()\n",
        "        curr_label = label.item()\n",
        "        curr_output = output.item()\n",
        "        #print(f\"Loss: {loss}\")\n",
        "        validation_results['validation_loss'].append(curr_loss)\n",
        "        validation_results['validation_true_label'].append(curr_label)\n",
        "        validation_results['validation_pred'].append(curr_output)\n",
        "\n",
        "        # accuracy\n",
        "        acc = (output.round() == label).float().mean()\n",
        "        acc = float(acc)\n",
        "        #print(f\"Accuracy: {acc}\")\n",
        "        accuracy[\"validation_accuracy\"].append(acc) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSvQpB6xyiYZ"
      },
      "outputs": [],
      "source": [
        "validation_results_df = pd.DataFrame(validation_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMCUgz2r21KZ"
      },
      "outputs": [],
      "source": [
        "validation_results_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnxbQ_YsTwh1"
      },
      "outputs": [],
      "source": [
        "#validation_results_df.to_csv(\"/content/validation_results_df_SMOTE_100epoch_500batch.csv.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Btv0M50u3Qmx"
      },
      "outputs": [],
      "source": [
        "fpr, tpr, thresholds = roc_curve(validation_results_df.validation_true_label, \n",
        "                                 validation_results_df.validation_pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, label='AUC = %0.4f'% roc_auc)\n",
        "plt.legend(loc='lower right')\n",
        "plt.plot([0,1],[0,1],'r--')\n",
        "plt.xlim([-0.001, 1])\n",
        "plt.ylim([0, 1.001])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7sHz3eX3see"
      },
      "outputs": [],
      "source": [
        "precision, recall, thresholds = precision_recall_curve(validation_results_df.validation_true_label, \n",
        "                                 validation_results_df.validation_pred)\n",
        "\n",
        "plt.plot(recall, precision, 'b', label='Precision-Recall curve')\n",
        "plt.title('Recall vs Precision')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwCVjFrr4JZU"
      },
      "outputs": [],
      "source": [
        "class_names = [\"Normal\", \"Fraud\"]\n",
        "cr = classification_report(validation_results_df.validation_true_label, \n",
        "                                 validation_results_df.validation_pred.round(),\n",
        "                      target_names=class_names,\n",
        "                      output_dict=True) \n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDRC2HgFpQJp"
      },
      "outputs": [],
      "source": [
        "cr[\"Normal\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKUdX882xDTW"
      },
      "outputs": [],
      "source": [
        "cr[\"Fraud\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnlN_N-25FBa"
      },
      "outputs": [],
      "source": [
        "confusion_matrix(validation_results_df.validation_true_label, \n",
        "                                 validation_results_df.validation_pred.round())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2pzY8h1T-ZU"
      },
      "outputs": [],
      "source": [
        "f1_score(validation_results_df.validation_true_label, \n",
        "                                 validation_results_df.validation_pred.round())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0AJs5BL5CEI"
      },
      "outputs": [],
      "source": [
        "precision_score(validation_results_df.validation_true_label, \n",
        "                                 validation_results_df.validation_pred.round())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQukdUoF5J_o"
      },
      "outputs": [],
      "source": [
        "recall_score(validation_results_df.validation_true_label, \n",
        "                                 validation_results_df.validation_pred.round())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgnFt4ya5MX1"
      },
      "outputs": [],
      "source": [
        "sum(accuracy[\"validation_accuracy\"])/len(accuracy[\"validation_accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTgXDMR1y9Cp"
      },
      "source": [
        "## Test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwyfLJu9y97N"
      },
      "outputs": [],
      "source": [
        "# Store results for plotting \n",
        "test_results = {}\n",
        "test_results['test_loss'] = []\n",
        "test_results['test_pred'] = []\n",
        "test_results['test_true_label'] = []\n",
        "\n",
        "# Evaluate accuracy on validation data \n",
        "curr_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, label in test_loader:\n",
        "        # move data and label to device\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        output = curr_model(data).to(device)\n",
        "        #print(f\"Output: {output}\")\n",
        "\n",
        "        # store relevant values \n",
        "        curr_loss = criterion(output, label).item()\n",
        "        curr_label = label.item()\n",
        "        curr_output = output.item()\n",
        "        print(f\"Loss: {loss}\")\n",
        "        test_results['test_loss'].append(curr_loss)\n",
        "        test_results['test_true_label'].append(curr_label)\n",
        "        test_results['test_pred'].append(curr_output)\n",
        "\n",
        "        # accuracy\n",
        "        acc = (output.round() == label).float().mean()\n",
        "        acc = float(acc)\n",
        "        #print(f\"Accuracy: {acc}\")\n",
        "        accuracy[\"validation_accuracy\"].append(acc) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tp5-u18wzS3B"
      },
      "outputs": [],
      "source": [
        "test_results_df = pd.DataFrame(test_results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(accuracy[\"validation_accuracy\"])/len(accuracy[\"validation_accuracy\"])"
      ],
      "metadata": {
        "id": "ehrOl4wKu31P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(test_results_df.test_true_label, \n",
        "                                 test_results_df.test_pred.round())"
      ],
      "metadata": {
        "id": "fMxo3bGJu7iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Mru4MSf062F"
      },
      "outputs": [],
      "source": [
        "fpr, tpr, thresholds = roc_curve(test_results_df.test_true_label, \n",
        "                                 test_results_df.test_pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, label='AUC = %0.4f'% roc_auc)\n",
        "plt.legend(loc='lower right')\n",
        "plt.plot([0,1],[0,1],'r--')\n",
        "plt.xlim([-0.001, 1])\n",
        "plt.ylim([0, 1.001])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gARODVt1KYs"
      },
      "outputs": [],
      "source": [
        "precision, recall, thresholds = precision_recall_curve(test_results_df.test_true_label, \n",
        "                                 test_results_df.test_pred)\n",
        "\n",
        "plt.plot(recall, precision, 'b', label='Precision-Recall curve')\n",
        "plt.title('Recall vs Precision')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qh9ouDfi1VKc"
      },
      "outputs": [],
      "source": [
        "class_names = [\"Normal\", \"Fraud\"]\n",
        "cr = classification_report(test_results_df.test_true_label, \n",
        "                                 test_results_df.test_pred.round(),\n",
        "                      target_names=class_names,\n",
        "                      output_dict=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3ieESim1kJ3"
      },
      "outputs": [],
      "source": [
        "cr[\"Normal\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h509DSbU1mBY"
      },
      "outputs": [],
      "source": [
        "cr[\"Fraud\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mnl2qsW51a9V"
      },
      "outputs": [],
      "source": [
        "confusion_matrix(test_results_df.test_true_label, \n",
        "                                 test_results_df.test_pred.round())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXZKb-W31p5z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}