{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rIkxALyPCv5J"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_edf\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_slice\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4s_zMYg1DGNx"
   },
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "75nfwJ_3LcEC"
   },
   "outputs": [],
   "source": [
    "#pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9z1blq3RDHEl"
   },
   "outputs": [],
   "source": [
    "train = np.load('/content/baseline_train_smote.npz')\n",
    "validation = np.load('/content/baseline_validation.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p0ZVQ1npNHZl"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\")\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 2\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 10\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s5iCaxAaDEUp"
   },
   "outputs": [],
   "source": [
    "# train\n",
    "X_train = torch.tensor(train[\"x\"], dtype=torch.float32).to(DEVICE)\n",
    "y_train = torch.tensor(train[\"y\"], dtype=torch.float32).reshape(-1,1).to(DEVICE)\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "\n",
    "# validation\n",
    "X_val = torch.tensor(validation[\"x\"], dtype=torch.float32).to(DEVICE)\n",
    "y_val = torch.tensor(validation[\"y\"], dtype=torch.float32).reshape(-1,1).to(DEVICE)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEX2boJeDbm7"
   },
   "source": [
    "## Optuna setup\n",
    "\n",
    "Followed tutorial on their website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57H36lAWGmye"
   },
   "outputs": [],
   "source": [
    "# Data loader \n",
    "def get_data():\n",
    "  train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=BATCHSIZE, \n",
    "                                           shuffle=True) \n",
    "  val_loader = torch.utils.data.DataLoader(val_dataset, \n",
    "                                           batch_size=BATCHSIZE, \n",
    "                                           shuffle=True)\n",
    "  return train_loader, val_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwTJO6cJE05q"
   },
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "  # Optimize number of layers, hidden units, dropout ratio\n",
    "  n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "  layers = []\n",
    "\n",
    "  in_features = 106\n",
    "  for i in range(n_layers):\n",
    "    out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 100)\n",
    "    layers.append(nn.Linear(in_features, out_features))\n",
    "    layers.append(nn.ReLU())\n",
    "    p = trial.suggest_float(\"dropout_l{}\".format(i), 0.4, 0.8)\n",
    "    layers.append(nn.Dropout(p))\n",
    "\n",
    "    in_features = out_features \n",
    "  layers.append(nn.Linear(in_features, 1))\n",
    "  layers.append(nn.Sigmoid())\n",
    "\n",
    "  return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GsI9JFbDZEs"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Get the dataset.\n",
    "    train_loader, valid_loader = get_data()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        pred_labels = []\n",
    "        true_labels = []\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.binary_cross_entropy(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        f1 = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                  break\n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.round() #output.argmax(dim=1, keepdim=True)\n",
    "                pred_labels.append(list(chain.from_iterable(pred.tolist())))\n",
    "                true_labels.append(list(chain.from_iterable(target.tolist())))\n",
    "\n",
    "\n",
    "        f1 = f1_score(true_labels, pred_labels, average=\"weighted\")\n",
    "\n",
    "        trial.report(f1, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return f1 #f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJkpwhOUK3Wr"
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SqwSh7cfN4gl"
   },
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72ooEOJMVgQ1"
   },
   "outputs": [],
   "source": [
    "plot_intermediate_values(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xE1Pl8VVqZS"
   },
   "outputs": [],
   "source": [
    "plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-xf17WVVvcu"
   },
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ppea7jEiV2Pw"
   },
   "outputs": [],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rgdcgkmGV8oe"
   },
   "outputs": [],
   "source": [
    "print(study.best_trial.value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5cnNKGiWk8E"
   },
   "outputs": [],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xppaACTiWp9F"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
